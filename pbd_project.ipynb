{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A POWER BI DASHBOARD PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Team: Team Namibia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement:\n",
    "Team Namibia has been assigned to design and deliver an end-to-end business intelligence solution. Our client has collected transactional data for the year 2019 but hasnâ€™t been able to put it to good use. The client hopes we can analyze the data and put together a report to help them find opportunities to drive more sales and work more efficiently. \n",
    "\n",
    "#### Objective\n",
    "In this analysis, we aim to:\n",
    "- Identify key trends and patterns in the 2019 transactional data.\n",
    "- Analyze sales performance and uncover opportunities to drive more sales.\n",
    "- Evaluate product performance and categorize products based on price levels.\n",
    "- Identify cities with the highest product deliveries.\n",
    "- Identify effective working processes\n",
    "\n",
    "#### Analytical Questions\n",
    "1. How much money did we make this year? \n",
    "   \n",
    "2. Can we identify any seasonality in the sales? \n",
    "\n",
    "3. What are our best and worst-selling products?\n",
    "\n",
    "4. How do sales compare to previous months or weeks?\n",
    "\n",
    "5. Which cities are our products delivered to most?\n",
    "\n",
    "6. How do product categories compare in revenue generated and quantities ordered?\n",
    "\n",
    "7. You are required to show additional details from your findings in your data. \n",
    "\n",
    "- NB: Products with unit prices above $99.99 should be labeled high-level products otherwise they should be basic level.\n",
    "\n",
    "#### Hypothesis\n",
    "- Null Hypothesis (H0): There are no significant differences in Amount amongst the group(columns) of factors being tested.\n",
    "- Alternative Hypothesis (H1): There are significant differences in Amount amongst the group(columns) of factors being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales data was collected for each month in the entire year of 2019. \n",
    "The data for the first half of the year (January to June) was collected in Excel and saved as CSV files before management decided to use databases to store their data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pyodbc library to handle ODBC database connections\n",
    "# Import the dotenv function to load environment variables from a .env file\n",
    "import pyodbc \n",
    "from dotenv import dotenv_values    \n",
    "\n",
    "# Import the warnings library to handle warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')       \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85625, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the folder path\n",
    "folder_path = r\"\\\\Mac\\Home\\Downloads\\Business-Analytics-Project\\dataset\"\n",
    "\n",
    "# Get a list of all CSV files\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "# Load all CSV files and concatenate them into a single DataFrame\n",
    "first_half = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
    "\n",
    "first_half.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load  Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establishing a connection to the SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DRIVER={SQL Server};SERVER=dap-projects-database.database.windows.net;DATABASE=dapDB;UID=capstone;PWD=Z7x@8pM$2w;MARS_Connection=yes;MinProtocolVersion=TLSv1.2;'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file into a dictionary\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the .env file\n",
    "database = environment_variables.get(\"DATABASE\")\n",
    "server = environment_variables.get(\"SERVER\")\n",
    "username = environment_variables.get(\"UID\")\n",
    "password = environment_variables.get(\"PWD\")\n",
    "\n",
    "# Create the connection string using the retrieved credentials\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\"\n",
    "connection_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sales_July_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales_August_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sales_September_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sales_October_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sales_November_2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sales_December_2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TABLE_NAME\n",
       "0       Sales_July_2019\n",
       "1     Sales_August_2019\n",
       "2  Sales_September_2019\n",
       "3    Sales_October_2019\n",
       "4   Sales_November_2019\n",
       "5   Sales_December_2019"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish a connection to the database using the connection string\n",
    "connection = pyodbc.connect(connection_string) \n",
    "\n",
    "# Define the SQL query to list all tables (for SQL Server)\n",
    "query = \"\"\"\n",
    "SELECT TABLE_NAME \n",
    "FROM INFORMATION_SCHEMA.TABLES \n",
    "WHERE TABLE_TYPE = 'BASE TABLE';\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query and fetch the result into a pandas DataFrame using the established database connection\n",
    "tables = pd.read_sql(query, connection)\n",
    "\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "july\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(14371, 6)\n",
      "==================================================\n",
      "august\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(12011, 6)\n",
      "==================================================\n",
      "september\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(11686, 6)\n",
      "==================================================\n",
      "october\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(20379, 6)\n",
      "==================================================\n",
      "november\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(17661, 6)\n",
      "==================================================\n",
      "december\n",
      "Index(['Order_ID', 'Product', 'Quantity_Ordered', 'Price_Each', 'Order_Date',\n",
      "       'Purchase_Address'],\n",
      "      dtype='object')\n",
      "(25117, 6)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Connection to each of the table\n",
    "query1 = \"Select * from Sales_July_2019\"\n",
    "query2 = \"Select * from Sales_August_2019\"\n",
    "query3 = \"Select * from Sales_September_2019\"\n",
    "query4 = \"Select * from Sales_October_2019\"\n",
    "query5 = \"Select * from Sales_November_2019\"\n",
    "query6 = \"Select * from Sales_December_2019\"\n",
    "\n",
    "# Execute the SQL query and fetch the result\n",
    "july_df = pd.read_sql(query1, connection)\n",
    "august_df = pd.read_sql(query2, connection)\n",
    "september_df = pd.read_sql(query3, connection)\n",
    "october_df = pd.read_sql(query4, connection)\n",
    "november_df = pd.read_sql(query5, connection)\n",
    "december_df = pd.read_sql(query6, connection)\n",
    "\n",
    "# Define the dictionary with DataFrames\n",
    "half_2 = {\n",
    "    'july': july_df,\n",
    "    'august': august_df,\n",
    "    'september': september_df,\n",
    "    'october': october_df,\n",
    "    'november': november_df,\n",
    "    'december': december_df\n",
    "}\n",
    "\n",
    "# Iterate over the dictionary\n",
    "for month, df in half_2.items():\n",
    "    print(f'{month}')\n",
    "    print(df.columns)\n",
    "    print(df.shape)\n",
    "    print('=' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second half of the year merged data: (101225, 6)\n"
     ]
    }
   ],
   "source": [
    "# Merge all DataFrames into one\n",
    "second_half = pd.concat(half_2, ignore_index=True)\n",
    "print('Second half of the year merged data:', second_half.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st half year data: 85625\n",
      "2st half year data: 101225\n",
      "Total year 2019 data: 186850\n"
     ]
    }
   ],
   "source": [
    "# Merging both halfs into 2019_df\n",
    "Merged_df = pd.concat([first_half, second_half], axis=0, ignore_index='True')\n",
    "\n",
    "print('1st half year data:', first_half.shape[0])\n",
    "print('2st half year data:', second_half.shape[0])\n",
    "print('Total year 2019 data:', Merged_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
